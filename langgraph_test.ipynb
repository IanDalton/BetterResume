{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(\n",
    "    file_path=\"jobs.csv\"\n",
    ")\n",
    "data = loader.load()\n",
    "from langchain_openai.chat_models.base import ChatOpenAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage,BaseMessage\n",
    "llm = ChatOpenAI(\n",
    "            base_url=\"http://localhost:1234/v1\",\n",
    "            api_key=\"not_needed\",\n",
    "            model=\"gemma-2-27b-it\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents added successfully.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "from langchain.tools import BaseTool\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from pydantic import Field, PrivateAttr\n",
    "\n",
    "class ChromaDBTool(BaseTool):\n",
    "    name: str = \"ChromaDBTool\"\n",
    "    description: str = (\n",
    "        \"A tool that interfaces with a ChromaDB database to retrieve information. \"\n",
    "        \"It initializes a connection to a specified collection and runs queries against it.\"\n",
    "    )\n",
    "    collection_name: str = Field(default=\"default_collection\")\n",
    "    persist_directory: str = Field(default=\"./chroma_db\")\n",
    "\n",
    "    # Declare private attributes for runtime-only properties.\n",
    "    _client: Any = PrivateAttr()\n",
    "    _collection: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._client = chromadb.Client(Settings(persist_directory=self.persist_directory))\n",
    "        try:\n",
    "            self._collection = self._client.get_collection(name=self.collection_name)\n",
    "        except Exception as e:\n",
    "            self._collection = self._client.create_collection(name=self.collection_name)\n",
    "      \n",
    "    def add_document(self, document: str, id: str):\n",
    "        \"\"\"\n",
    "        Add a document to the ChromaDB collection.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._collection.add(documents=[document], ids=[id])\n",
    "            return \"Document added successfully.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error adding document: {e}\"\n",
    "    def add_documents(self, documents: list, ids: list):\n",
    "        \"\"\"\n",
    "        Add multiple documents to the ChromaDB collection.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._collection.add(documents=documents, ids=ids)\n",
    "            return \"Documents added successfully.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error adding documents: {e}\"\n",
    "    def _run(self, query: str, **kwargs):\n",
    "        print(\"chromadb\")\n",
    "        \"\"\"\n",
    "        Synchronous method to query the ChromaDB collection.\n",
    "        Expects a text query and returns the query results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self._collection.query(query_texts=[query],n_results=2)\n",
    "            return list(zip(results[\"documents\"][0],results[\"distances\"][0]))\n",
    "        except Exception as e:\n",
    "            return f\"Error querying the database: {e}\"\n",
    "\n",
    "    async def _arun(self, query: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Asynchronous version of the _run method.\n",
    "        Currently, this calls the synchronous version for simplicity.\n",
    "        \"\"\"\n",
    "        return self._run(query, **kwargs)\n",
    "tool = ChromaDBTool()\n",
    "tool.add_documents([d.page_content for d in data], [str(i) for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromadb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"type: contract\\ncompany: Somos Feed\\nlocation: Argentina\\nrole: Data Architect\\nstart_date: 01/07/2024\\nend_date: 01/12/2024\\ndescription: Python, Django, Javascript, SQLite. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week's data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solutiopn also freed time of other data scientists in the team that were previously just cleaning data.\",\n",
       "  1.5428789854049683),\n",
       " ('type: non-profit\\ncompany: CEITBA\\nlocation: Argentina\\nrole: Lead Developer\\nstart_date: 01/03/2021\\nend_date: 01/03/2025\\ndescription: Python, Javascript, React, Dart, Flutter. Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses.',\n",
       "  1.5849837064743042)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"Java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_with_tools = llm.bind_tools([tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x19294fa21b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    print('chatbot message')\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x19294fa21b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        print('tools message')\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            print(tool_call[\"args\"])\n",
    "            tool_result = self.tools_by_name[\"ChromaDBTool\"].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            print(tool_result)\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ChromaDBTool': ChromaDBTool()}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node.tools_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "        state:State\n",
    "):\n",
    "    if isinstance(state, list):\n",
    "        message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(\"No message found in input\")\n",
    "    if hasattr(message, \"tool_calls\") and len(message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", route_tools ,{\"tools\": \"tools\", END: END})\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot message\n",
      "tools message\n",
      "{'query': 'SQL database design experience'}\n",
      "chromadb\n",
      "[('type: job\\ncompany: Accenture\\nlocation: Argentina\\nrole: Data Engineer\\nstart_date: 01/08/2024\\nend_date: \\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns', 1.4754233360290527), ('type: job\\ncompany: Turbodato\\nlocation: Argentina\\nrole: Data Architect\\nstart_date: 01/01/2024\\nend_date: 01/12/2024\\ndescription: Python, SQL, Azure Database. Designed and built the startup’s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Itaú Bank and Cebra Jugueterías. Created interactive dashboards using Power BI, enabling real-time decision-making.', 1.4990053176879883)]\n",
      "{'query': 'C# experience'}\n",
      "chromadb\n",
      "[('type: job\\ncompany: Accenture\\nlocation: Argentina\\nrole: Data Engineer\\nstart_date: 01/08/2024\\nend_date: \\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns', 1.5888159275054932), ('type: job\\ncompany: Better Resume\\nlocation: Argentina\\nrole: Software Developer\\nstart_date: 01/03/2025\\nend_date: \\ndescription: Python, Vector Database, fastapi. Developed a web app that the user can use to create a resume using LLMs and RAGs to generate a resume tailored to the specific position description. It was built using ChromaDB for the vector database, a locally hosted model and fastapi with a basic javascript frontend. The data is currently stored in a csv so the user can load and modify the data on a familiar format.', 1.638282299041748)]\n",
      "{'query': 'Azure Data Factory experience'}\n",
      "chromadb\n",
      "[('type: job\\ncompany: Accenture\\nlocation: Argentina\\nrole: Data Engineer\\nstart_date: 01/08/2024\\nend_date: \\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns', 1.0290191173553467), ('type: job\\ncompany: Turbodato\\nlocation: Argentina\\nrole: Data Architect\\nstart_date: 01/01/2024\\nend_date: 01/12/2024\\ndescription: Python, SQL, Azure Database. Designed and built the startup’s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Itaú Bank and Cebra Jugueterías. Created interactive dashboards using Power BI, enabling real-time decision-making.', 1.093881368637085)]\n",
      "{'query': 'data modeling experience'}\n",
      "chromadb\n",
      "[(\"type: contract\\ncompany: Somos Feed\\nlocation: Argentina\\nrole: Data Architect\\nstart_date: 01/07/2024\\nend_date: 01/12/2024\\ndescription: Python, Django, Javascript, SQLite. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week's data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solutiopn also freed time of other data scientists in the team that were previously just cleaning data.\", 1.2369258403778076), ('type: job\\ncompany: Accenture\\nlocation: Argentina\\nrole: Data Engineer\\nstart_date: 01/08/2024\\nend_date: \\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns', 1.3902695178985596)]\n",
      "{'query': 'experience with Power Apps'}\n",
      "chromadb\n",
      "[('type: non-profit\\ncompany: CEITBA\\nlocation: Argentina\\nrole: Lead Developer\\nstart_date: 01/03/2021\\nend_date: 01/03/2025\\ndescription: Python, Javascript, React, Dart, Flutter. Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses.', 1.29900324344635), ('type: job\\ncompany: Turbodato\\nlocation: Argentina\\nrole: Data Architect\\nstart_date: 01/01/2024\\nend_date: 01/12/2024\\ndescription: Python, SQL, Azure Database. Designed and built the startup’s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Itaú Bank and Cebra Jugueterías. Created interactive dashboards using Power BI, enabling real-time decision-making.', 1.391035556793213)]\n",
      "chatbot message\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"You are BetterResume, an open-source tool that helps users create the best possible resumes optimized for ATS AI scanners.  \n",
    "\n",
    "The user has granted you access to their full job experience, which is stored in a vector database. You can retrieve relevant information from this database by calling `ChromaDBTool` with the argument `query: str`. This will return the most relevant job experience for inclusion in the resume.  \n",
    "\n",
    "**Instructions:**  \n",
    "1. **Make at least one call to `ChromaDBTool`** to retrieve relevant experience.  \n",
    "2. **Make multiple tool calls (at least 4!) according to the different skills asked for in the description** to gather more data.  \n",
    "3. **Wait for the tool's response(s), then format and return the information as a structured JSON object.**  \n",
    "4. **Extract skills, languages, and technologies ONLY if they are explicitly mentioned in the retrieved job descriptions.**  \n",
    "5. **Include at least 3 experiences in the resume output.** It doesnt have to be a job, can be other stuf like contract, volunteer, etc.\n",
    "6. **Ensure the output follows this JSON format:**  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"resume_section\": {\n",
    "    \"title\": \"Title describing the job that the user is applying for\",\n",
    "    \"experience\": [\n",
    "      {\n",
    "        \"position\": \"Job Title\",\n",
    "        \"company\": \"Company Name\",\n",
    "        \"location\": \"Location\",\n",
    "        \"start_date\": \"Month Year\",\n",
    "        \"end_date\": \"Month Year or Present\",\n",
    "        \"description\": \"Detailed job description and achievements.\"\n",
    "      }\n",
    "    ],\n",
    "    \"skills\": {\n",
    "      \"languages\": [\"List of programming languages\"],\n",
    "      \"databases\": [\"List of databases\"],\n",
    "      \"tools_and_technologies\": [\"List of tools, frameworks, and methodologies\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "Do not include additional text, explanations, or formatting outside of the JSON output.\n",
    "\n",
    "Do not include languages that are not implied by the database query.\n",
    "\n",
    "Ensure consistency in date formatting and job descriptions to maintain a professional resume output.\n",
    "\n",
    "If you understand, proceed with handling the user request.\n",
    "\"\"\"\n",
    "\n",
    "JOB_PROMPT = \"\"\"About the job\n",
    "Job Description: Azure & SQL Data Engineer\n",
    "\n",
    " \n",
    "\n",
    "As a Data Engineer, you will be responsible for designing, implementing, and maintaining data solutions with a strong focus on SQL databases. You will collaborate with cross-functional teams to gather requirements, design efficient and robust SQL queries, and ensure data integrity and security.\n",
    "\n",
    " \n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "\n",
    "\n",
    "· Collaborate with stakeholders to gather data requirements and translate them into technical specifications.\n",
    "\n",
    "· Build and optimize SQL queries for data ingestion, transformation, and storage.\n",
    "\n",
    "· Utilize Azure Data Factory for data orchestration and workflow automation.\n",
    "\n",
    "· Monitor and troubleshoot SQL databases to ensure performance and availability.\n",
    "\n",
    "· Work closely with data scientists and analysts to support their data needs through optimized SQL queries and reporting tools.\n",
    "\n",
    "· Stay up-to-date with the latest trends and advancements in SQL data engineering and recommend best practices to enhance data solutions.\n",
    "\n",
    " \n",
    "\n",
    "Qualifications:\n",
    "\n",
    "\n",
    "\n",
    "· 3+ years of proven experience as a data engineer with a strong focus on SQL.\n",
    "\n",
    "· Strong expertise in C#, SQL and extensive experience with data modeling and database design.\n",
    "\n",
    "· Excellent problem-solving and analytical skills.\n",
    "\n",
    "· Knowledge of data governance and data security principles.\n",
    "\n",
    "· Strong communication and collaboration abilities.\n",
    "\n",
    "· It is desired familiarity with Power Apps.\n",
    "\n",
    "· Ideally, but not mandatory, familiarity with Azure data services such as Azure SQL Database, Azure Data Factory, etc.\"\"\"\n",
    "\n",
    "response = graph.invoke({\"messages\": [{\"role\": \"system\", \"content\": PROMPT},\n",
    "                           {\"role\": \"user\", \"content\": JOB_PROMPT}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"resume_section\": {\n",
       "    \"title\": \"Azure & SQL Data Engineer\",\n",
       "    \"experience\": [\n",
       "      {\n",
       "        \"position\": \"Data Engineer\",\n",
       "        \"company\": \"Accenture\",\n",
       "        \"location\": \"Argentina\",\n",
       "        \"start_date\": \"01/08/2024\",\n",
       "        \"end_date\": \"Present\",\n",
       "        \"description\": \"Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\"\n",
       "      },\n",
       "      {\n",
       "        \"position\": \"Data Architect\",\n",
       "        \"company\": \"Turbodato\",\n",
       "        \"location\": \"Argentina\",\n",
       "        \"start_date\": \"01/01/2024\",\n",
       "        \"end_date\": \"01/12/2024\",\n",
       "        \"description\": \"Designed and built the startup’s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Itaú Bank and Cebra Jugueterías. Created interactive dashboards using Power BI, enabling real-time decision-making.\"\n",
       "      },\n",
       "      {\n",
       "        \"position\": \"Lead Developer\",\n",
       "        \"company\": \"CEITBA\",\n",
       "        \"location\": \"Argentina\",\n",
       "        \"start_date\": \"01/03/2021\",\n",
       "        \"end_date\": \"01/03/2025\",\n",
       "        \"description\": \"Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses.\"\n",
       "      }\n",
       "\n",
       "    ],\n",
       "    \"skills\": {\n",
       "      \"languages\": [\"Python\", \"Javascript\", \"SQL\"],\n",
       "      \"databases\": [\"Azure SQL Database\", \"SQLite\"],\n",
       "      \"tools_and_technologies\": [\"LangChain\", \"RAGs\",\"Power BI\",\"Flutter\",\"Firebase\",\"Google Cloud\",\"Django\",\"chromaDB\", \"github actions\",\"CI/CD\"]\n",
       "    }\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = response[\"messages\"][-1].content\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [SystemMessage(content='You are BetterResume, an open-source tool that helps users create the best possible resumes optimized for ATS AI scanners.  \\n\\nThe user has granted you access to their full job experience, which is stored in a vector database. You can retrieve relevant information from this database by calling `ChromaDBTool` with the argument `query: str`. This will return the most relevant job experience for inclusion in the resume.  \\n\\n**Instructions:**  \\n1. **Make at least one call to `ChromaDBTool`** to retrieve relevant experience.  \\n2. **Make multiple tool calls (at least 4!) according to the different skills asked for in the description** to gather more data.  \\n3. **Wait for the tool\\'s response(s), then format and return the information as a structured JSON object.**  \\n4. **Extract skills, languages, and technologies ONLY if they are explicitly mentioned in the retrieved job descriptions.**  \\n5. **Include at least 3 experiences in the resume output.** It doesnt have to be a job, can be other stuf like contract, volunteer, etc.\\n6. **Ensure the output follows this JSON format:**  \\n\\n```json\\n{\\n  \"resume_section\": {\\n    \"title\": \"Title describing the job that the user is applying for\",\\n    \"experience\": [\\n      {\\n        \"position\": \"Job Title\",\\n        \"company\": \"Company Name\",\\n        \"location\": \"Location\",\\n        \"start_date\": \"Month Year\",\\n        \"end_date\": \"Month Year or Present\",\\n        \"description\": \"Detailed job description and achievements.\"\\n      }\\n    ],\\n    \"skills\": {\\n      \"languages\": [\"List of programming languages\"],\\n      \"databases\": [\"List of databases\"],\\n      \"tools_and_technologies\": [\"List of tools, frameworks, and methodologies\"]\\n    }\\n  }\\n}\\n```\\nDo not include additional text, explanations, or formatting outside of the JSON output.\\n\\nDo not include languages that are not implied by the database query.\\n\\nEnsure consistency in date formatting and job descriptions to maintain a professional resume output.\\n\\nIf you understand, proceed with handling the user request.\\n', additional_kwargs={}, response_metadata={}, id='60b7b692-78d2-483d-9703-22aab803d270'),\n",
       "  HumanMessage(content='About the job\\nJob Description: Azure & SQL Data Engineer\\n\\n \\n\\nAs a Data Engineer, you will be responsible for designing, implementing, and maintaining data solutions with a strong focus on SQL databases. You will collaborate with cross-functional teams to gather requirements, design efficient and robust SQL queries, and ensure data integrity and security.\\n\\n \\n\\nResponsibilities:\\n\\n\\n\\n· Collaborate with stakeholders to gather data requirements and translate them into technical specifications.\\n\\n· Build and optimize SQL queries for data ingestion, transformation, and storage.\\n\\n· Utilize Azure Data Factory for data orchestration and workflow automation.\\n\\n· Monitor and troubleshoot SQL databases to ensure performance and availability.\\n\\n· Work closely with data scientists and analysts to support their data needs through optimized SQL queries and reporting tools.\\n\\n· Stay up-to-date with the latest trends and advancements in SQL data engineering and recommend best practices to enhance data solutions.\\n\\n \\n\\nQualifications:\\n\\n\\n\\n· 3+ years of proven experience as a data engineer with a strong focus on SQL.\\n\\n· Strong expertise in C#, SQL and extensive experience with data modeling and database design.\\n\\n· Excellent problem-solving and analytical skills.\\n\\n· Knowledge of data governance and data security principles.\\n\\n· Strong communication and collaboration abilities.\\n\\n· It is desired familiarity with Power Apps.\\n\\n· Ideally, but not mandatory, familiarity with Azure data services such as Azure SQL Database, Azure Data Factory, etc.', additional_kwargs={}, response_metadata={}, id='a2015182-8f87-4bfc-8e1d-14e234e837c8'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '585556856', 'function': {'arguments': '{\"query\":\"SQL database design experience\"}', 'name': 'ChromaDBTool'}, 'type': 'function'}, {'id': '638706666', 'function': {'arguments': '{\"query\":\"C# experience\"}', 'name': 'ChromaDBTool'}, 'type': 'function'}, {'id': '639396153', 'function': {'arguments': '{\"query\":\"Azure Data Factory experience\"}', 'name': 'ChromaDBTool'}, 'type': 'function'}, {'id': '680995616', 'function': {'arguments': '{\"query\":\"data modeling experience\"}', 'name': 'ChromaDBTool'}, 'type': 'function'}, {'id': '464654937', 'function': {'arguments': '{\"query\":\"experience with Power Apps\"}', 'name': 'ChromaDBTool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 1185, 'total_tokens': 1363, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-2-27b-it', 'system_fingerprint': 'gemma-2-27b-it', 'id': 'chatcmpl-h8mx0en0ht43zbh3qkfn1t', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2d01b9b1-fe44-4a1e-83ac-79b1b2e9758e-0', tool_calls=[{'name': 'ChromaDBTool', 'args': {'query': 'SQL database design experience'}, 'id': '585556856', 'type': 'tool_call'}, {'name': 'ChromaDBTool', 'args': {'query': 'C# experience'}, 'id': '638706666', 'type': 'tool_call'}, {'name': 'ChromaDBTool', 'args': {'query': 'Azure Data Factory experience'}, 'id': '639396153', 'type': 'tool_call'}, {'name': 'ChromaDBTool', 'args': {'query': 'data modeling experience'}, 'id': '680995616', 'type': 'tool_call'}, {'name': 'ChromaDBTool', 'args': {'query': 'experience with Power Apps'}, 'id': '464654937', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1185, 'output_tokens': 178, 'total_tokens': 1363, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\", 1.4754233360290527], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup\\\\u2019s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita\\\\u00fa Bank and Cebra Jugueter\\\\u00edas. Created interactive dashboards using Power BI, enabling real-time decision-making.\", 1.4990053176879883]]', name='ChromaDBTool', id='4f86cb1a-fb6c-42ec-a641-f767702ebb93', tool_call_id='585556856'),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\", 1.5888159275054932], [\"type: job\\\\ncompany: Better Resume\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/03/2025\\\\nend_date: \\\\ndescription: Python, Vector Database, fastapi. Developed a web app that the user can use to create a resume using LLMs and RAGs to generate a resume tailored to the specific position description. It was built using ChromaDB for the vector database, a locally hosted model and fastapi with a basic javascript frontend. The data is currently stored in a csv so the user can load and modify the data on a familiar format.\", 1.638282299041748]]', name='ChromaDBTool', id='3216b793-a26c-40a8-b80e-cf2a8839751d', tool_call_id='638706666'),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\", 1.0290191173553467], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup\\\\u2019s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita\\\\u00fa Bank and Cebra Jugueter\\\\u00edas. Created interactive dashboards using Power BI, enabling real-time decision-making.\", 1.093881368637085]]', name='ChromaDBTool', id='35b38596-639f-4d18-a662-30226f925caa', tool_call_id='639396153'),\n",
       "  ToolMessage(content='[[\"type: contract\\\\ncompany: Somos Feed\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/07/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, Django, Javascript, SQLite. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week\\'s data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solutiopn also freed time of other data scientists in the team that were previously just cleaning data.\", 1.2369258403778076], [\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\", 1.3902695178985596]]', name='ChromaDBTool', id='c7399500-e40e-4ef8-bacc-7ca00e793757', tool_call_id='680995616'),\n",
       "  ToolMessage(content='[[\"type: non-profit\\\\ncompany: CEITBA\\\\nlocation: Argentina\\\\nrole: Lead Developer\\\\nstart_date: 01/03/2021\\\\nend_date: 01/03/2025\\\\ndescription: Python, Javascript, React, Dart, Flutter. Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses.\", 1.29900324344635], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup\\\\u2019s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita\\\\u00fa Bank and Cebra Jugueter\\\\u00edas. Created interactive dashboards using Power BI, enabling real-time decision-making.\", 1.391035556793213]]', name='ChromaDBTool', id='18f5738e-9aed-490f-ad74-61772513bb7b', tool_call_id='464654937'),\n",
       "  AIMessage(content='```json\\n{\\n  \"resume_section\": {\\n    \"title\": \"Azure & SQL Data Engineer\",\\n    \"experience\": [\\n      {\\n        \"position\": \"Data Engineer\",\\n        \"company\": \"Accenture\",\\n        \"location\": \"Argentina\",\\n        \"start_date\": \"01/08/2024\",\\n        \"end_date\": \"Present\",\\n        \"description\": \"Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns\"\\n      },\\n      {\\n        \"position\": \"Data Architect\",\\n        \"company\": \"Turbodato\",\\n        \"location\": \"Argentina\",\\n        \"start_date\": \"01/01/2024\",\\n        \"end_date\": \"01/12/2024\",\\n        \"description\": \"Designed and built the startup’s backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Itaú Bank and Cebra Jugueterías. Created interactive dashboards using Power BI, enabling real-time decision-making.\"\\n      },\\n      {\\n        \"position\": \"Lead Developer\",\\n        \"company\": \"CEITBA\",\\n        \"location\": \"Argentina\",\\n        \"start_date\": \"01/03/2021\",\\n        \"end_date\": \"01/03/2025\",\\n        \"description\": \"Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses.\"\\n      }\\n\\n    ],\\n    \"skills\": {\\n      \"languages\": [\"Python\", \"Javascript\", \"SQL\"],\\n      \"databases\": [\"Azure SQL Database\", \"SQLite\"],\\n      \"tools_and_technologies\": [\"LangChain\", \"RAGs\",\"Power BI\",\"Flutter\",\"Firebase\",\"Google Cloud\",\"Django\",\"chromaDB\", \"github actions\",\"CI/CD\"]\\n    }\\n  }\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 551, 'prompt_tokens': 3097, 'total_tokens': 3648, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-2-27b-it', 'system_fingerprint': 'gemma-2-27b-it', 'id': 'chatcmpl-5z3w7lzdbwfi6fccpnaggq', 'finish_reason': 'stop', 'logprobs': None}, id='run-f56d5b24-b1e1-4e01-9aec-3408ecc262f4-0', usage_metadata={'input_tokens': 3097, 'output_tokens': 551, 'total_tokens': 3648, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
