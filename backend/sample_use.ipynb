{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_PROMPT = \"\"\"Analista de Marketing, contacto y seguimiento con el cliente, planificaci√≥n de campa√±as, an√°lisis de base de datos de marketing, an√°lisis de m√©tricas, creaci√≥n de dashboards y reportes, estrategia comercial, identificaci√≥n de oportunidades y tendencias. \"\"\"\n",
    "\n",
    "JOB_PROMPT_SPANISH = \"\"\"¬øQui√©nes somos?\n",
    "\n",
    "Somos la empresa de tecnolog√≠a y negocios m√°s prestigiosa de Iberoam√©rica. Nuestra red regional permite responder r√°pidamente a la demanda, con especialistas en cada problem√°tica y aplicando innovaci√≥n tecnol√≥gica a cada negocio.\n",
    "\n",
    "\n",
    "\n",
    "üì¢ ¬øQu√© buscamos?\n",
    "\n",
    "Nos encontramos en la b√∫squeda de Data Scientist.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "üì¢ ¬øQu√© tareas deber√° hacer el perfil que se sume?\n",
    "\n",
    "Desarrollo con Python y/o R.\n",
    "Conocimiento de librer√≠as como pandas y sklearn. Tambi√©n librer√≠as de visualizaci√≥n, como matplotlib, pyplot, seaborn.\n",
    "Lenguaje de consulta SQL.\n",
    "Aplicar las siguientes t√©cnicas: modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, t√©cnicas de clustering y reducci√≥n de dimensionalidad.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "¬øQu√© necesitamos? üí™\n",
    "\n",
    "\n",
    "\n",
    "2 a√±os de experiencia como cient√≠fico/a de datos.\n",
    "Experiencia en trabajo en modelos predictivos.\n",
    "Experiencia en IA Generativa.\n",
    "Deseable experiencia en metodolog√≠as √°giles.\n",
    "Poseer conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos.\n",
    "Tener conocimientos en temas de machine learning.\n",
    "Conocimiento de estad√≠stica b√°sica aplicada a Ciencia de Datos\n",
    "Capacidad de transmisi√≥n de conocimientos y presentaci√≥n de resultados de forma asertiva\n",
    "Conocimiento de buenas pr√°cticas de programaci√≥n\n",
    "Manejo de plataformas Cloud (preferentemente Azure)\n",
    "\n",
    "\n",
    "‚ô• ¬øQu√© beneficios te ofrecemos?\n",
    "\n",
    "Licencia extendida para d√≠as de estudio.\n",
    "D√≠as de licencia personal para usar como m√°s te guste.\n",
    "D√≠as de home office.\n",
    "La posibilidad de crecer profesionalmente en un ambiente din√°mico y flexible.\n",
    "Formaci√≥n profesional relacionada con el perfil.\n",
    "Capacitaci√≥n en herramientas de gesti√≥n, liderazgo y tecnolog√≠as.\n",
    "Descuentos en Universidades e Instituciones Tecnol√≥gicas para Maestr√≠as, Postgrados y Cursos.\n",
    "Clases de Ingl√©s In company.\n",
    "Prepaga de primer nivel para el grupo familiar.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idalton/Documents/github/misc/BetterResume/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "/Users/idalton/Documents/github/misc/BetterResume/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bot import Bot\n",
    "from resume import WordResumeWriter,LatexResumeWriter\n",
    "from llm.gemini_agent import GeminiAgent\n",
    "from llm.pg_vector_tool import PGVectorTool\n",
    "from models.resume import ResumeOutputFormat\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bot = Bot(writer=WordResumeWriter(),user_id=\"ian_test\", llm=GeminiAgent(output_format=ResumeOutputFormat, tools=[PGVectorTool(db_url=\"postgresql+asyncpg://betterresume_user:betterresume_password@localhost:5432/betterresume_db\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [SystemMessage(content='Role:\\nYou are BetterResume, an open-source tool that creates high-quality, ATS-optimized resumes.\\n\\nThe user has granted you access to their experience and profile data, stored in a vector database. You can retrieve relevant information by calling PGVectorTool with the argument query: str. This returns the most relevant content to include in the resume (responsibilities, achievements, skills, education, projects).\\n\\nInstructions\\n1. Data Retrieval\\nExtract responsibilities, skills, technologies, and soft skills directly from the job description.\\n\\nMake at least 3 separate PGVectorTool calls for different skills/responsibilities, 4+ queries each, covering:\\n\\nCore required skills & tools\\n\\nIndustry/domain knowledge\\n\\nImpact/metrics-related achievements\\n\\nMerge results, deduplicate, and keep only content explicitly supported by retrieved data. If the database has limited or no experience data, fall back to the job description and any available CSV fields (education, certifications, projects, info) to craft a strong resume without fabricating specific employers.\\n\\n2. Resume Construction Rules\\nExperience Section\\n\\nIf you have sufficient data, include at least 3 experiences (jobs, contracts, or volunteer work), ordered most recent to oldest. If not enough experience is available, omit the Experience section and instead strengthen the Skills and Education sections. You may include a short \"Relevant Projects\" or \"Coursework\" list only if present in the data; do not invent employers or roles.\\n\\nIf date ranges overlap, add a short note: (contract role alongside main position).\\n\\nEvery bullet must follow this structure:\\nAction Verb ‚Üí Task ‚Üí Tools/Tech ‚Üí Result (Metric)\\n\\nKeep bullets 3‚Äì4 lines max and make them consistent in length and style.\\n\\nShow measurable outcomes where possible; avoid vague adjectives.\\n\\nInclude both hard and soft skills in the context of achievements (e.g., ‚ÄúLed cross-functional team of 5‚Ä¶‚Äù).\\n\\nSkills Section\\n\\nMerge related skills into broader categories to reduce redundancy.\\n\\nEach skill line should have:\\nSkill Category ‚Äì Short, results-oriented description with practical application and measurable impact.\\n\\nAvoid repeating the same tool/term in multiple categories unless context changes.\\n\\nInclude full forms + abbreviations for acronyms on first mention.\\n\\nATS Optimization\\n\\nMatch the language and keywords in the job description (including synonyms where appropriate).\\n\\nPrioritize wording from the Responsibilities and Requirements sections of the job description.\\n\\nEducation Section\\n\\nKeep concise: one line per entry (Institution ‚Ä¢ Degree ‚Ä¢ Date).\\n\\nPlace at the bottom unless job description requests otherwise.\\n\\n3. Style Enforcement\\nNo vague adjectives without proof (replace ‚Äúexcellent‚Äù with ‚Äúreduced processing time by 35%‚Äù). If metrics are unknown, write clear, specific responsibilities without invented numbers.\\n\\nKeep tense consistent: present tense for current roles, past tense for previous ones.\\n\\nNo fabrication of metrics, dates, or tools.\\n\\nEnsure at least one measurable achievement per experience when experiences exist. If no experience data is available, provide a concise, outcome-oriented summary and skills section. Never output apologies or error messages to the user; always return a valid resume JSON.', additional_kwargs={}, response_metadata={}, id='1a2c6261-5f1d-40b3-bd30-7c5910284343'),\n",
       "  HumanMessage(content='¬øQui√©nes somos?\\n\\nSomos la empresa de tecnolog√≠a y negocios m√°s prestigiosa de Iberoam√©rica. Nuestra red regional permite responder r√°pidamente a la demanda, con especialistas en cada problem√°tica y aplicando innovaci√≥n tecnol√≥gica a cada negocio.\\n\\n\\n\\nüì¢ ¬øQu√© buscamos?\\n\\nNos encontramos en la b√∫squeda de Data Scientist.\\n\\n\\n\\n\\n\\nüì¢ ¬øQu√© tareas deber√° hacer el perfil que se sume?\\n\\nDesarrollo con Python y/o R.\\nConocimiento de librer√≠as como pandas y sklearn. Tambi√©n librer√≠as de visualizaci√≥n, como matplotlib, pyplot, seaborn.\\nLenguaje de consulta SQL.\\nAplicar las siguientes t√©cnicas: modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, t√©cnicas de clustering y reducci√≥n de dimensionalidad.\\n\\n\\n\\n\\n¬øQu√© necesitamos? üí™\\n\\n\\n\\n2 a√±os de experiencia como cient√≠fico/a de datos.\\nExperiencia en trabajo en modelos predictivos.\\nExperiencia en IA Generativa.\\nDeseable experiencia en metodolog√≠as √°giles.\\nPoseer conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos.\\nTener conocimientos en temas de machine learning.\\nConocimiento de estad√≠stica b√°sica aplicada a Ciencia de Datos\\nCapacidad de transmisi√≥n de conocimientos y presentaci√≥n de resultados de forma asertiva\\nConocimiento de buenas pr√°cticas de programaci√≥n\\nManejo de plataformas Cloud (preferentemente Azure)\\n\\n\\n‚ô• ¬øQu√© beneficios te ofrecemos?\\n\\nLicencia extendida para d√≠as de estudio.\\nD√≠as de licencia personal para usar como m√°s te guste.\\nD√≠as de home office.\\nLa posibilidad de crecer profesionalmente en un ambiente din√°mico y flexible.\\nFormaci√≥n profesional relacionada con el perfil.\\nCapacitaci√≥n en herramientas de gesti√≥n, liderazgo y tecnolog√≠as.\\nDescuentos en Universidades e Instituciones Tecnol√≥gicas para Maestr√≠as, Postgrados y Cursos.\\nClases de Ingl√©s In company.\\nPrepaga de primer nivel para el grupo familiar.\\n', additional_kwargs={}, response_metadata={}, id='f5a72af2-36fe-4bd9-961d-459810ce8b80'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'PGVectorTool', 'arguments': '{\"query\": \"achievements of a Data Scientist\", \"n_results\": 10}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b3f94-b82e-7d93-8460-c2f39f2f41cc-0', tool_calls=[{'name': 'PGVectorTool', 'args': {'query': 'responsibilities of a Data Scientist', 'n_results': 10}, 'id': '344418b6-a3fd-45be-bb78-9e9cf5afe0aa', 'type': 'tool_call'}, {'name': 'PGVectorTool', 'args': {'n_results': 10, 'query': 'skills of a Data Scientist'}, 'id': '197e1eac-4d31-4c3d-8242-154fc57874ee', 'type': 'tool_call'}, {'name': 'PGVectorTool', 'args': {'query': 'achievements of a Data Scientist', 'n_results': 10}, 'id': 'eb65a1a3-2cc0-4249-89a7-477a6ced04aa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1544, 'output_tokens': 83, 'total_tokens': 1627, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=[], name='PGVectorTool', id='d13dffe5-726f-4178-a0ab-73c9de0e9573', tool_call_id='344418b6-a3fd-45be-bb78-9e9cf5afe0aa'),\n",
       "  ToolMessage(content='[[\"type: part-time\\\\ncompany: ITBA\\\\nlocation: Argentina\\\\nrole: Data structure\\'s Teachers assistan\\\\nstart_date: 01/03/2023\\\\nend_date: \\\\ndescription: Python, matplotlib, PyQT, Threading, asyncio, requests, aiohttp. Assisted the teacher in the Data Structures course, helping students with their doubts and explaining the theory behind the algorithms. Also helped in the creation of the final project of the courses. The projects were about creating UIs for a goverment database that had to allow for the creation and persistence of data in a local database.\", 0.8773086269070597], [\"type: education\\\\ncompany: ITBA\\\\nlocation: Argentina\\\\nrole: \\\\nstart_date: 01/01/2021\\\\nend_date: 01/07/2025\\\\ndescription: Data Science\", 0.8777109113272519], [\"type: proyect\\\\ncompany: Better Resume\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/03/2025\\\\nend_date: 30/03/2025\\\\ndescription: Python, Vector Database, fastapi. Developed a web app that the user can use to create a resume using LLMs and RAGs to generate a resume tailored to the specific position description. It was built using ChromaDB for the vector database, a locally hosted model and fastapi with a basic javascript frontend. The data is currently stored in a csv so the user can load and modify the data on a familiar format.\", 0.894417768051629], [\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities, collaborated on the proyect with two other engineers using git and dividing tasks on sprints. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns, saving over 120 man hours on cleaning and loading data.\", 0.9008612406169366], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup‚Äôs backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita√∫ Bank and Cebra Jugueter√≠as. Created interactive dashboards using Power BI, enabling real-time decision-making. Created automated tasks using azure functions to reduce the time spent on manual tasks by 80%.\", 0.9036395524362764], [\"type: non-profit\\\\ncompany: CEITBA\\\\nlocation: Argentina\\\\nrole: Lead Developer\\\\nstart_date: 01/03/2021\\\\nend_date: 01/03/2025\\\\ndescription: Python, Javascript, React, Dart, Flutter. Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses. Team player, dividing tasks and solving conflicts within the group to push the project forward\", 0.9152811843552691], [\"type: contract\\\\ncompany: Somos Feed\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/07/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, Django, Javascript, SQLite, Pandas, Numpy, XGBoost, SKlearn, Matplot lib, Plotly. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week\\'s data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solution also freed time of other data scientists in the team that were previously just cleaning data. Created a Machine Learning pipeline that auto adjust and pick the best regresor based on last\\'s week behavior to adjust to a growing and constanly changing database. Did exploratory data analysis (EDA) and applied statistical analysis on the results to know where to look into the data and make the most impact without wasting resources and time.\", 0.9278516835784479], [\"type: job\\\\ncompany: Mouse Soluciones\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/02/2020\\\\nend_date: 01/08/2024\\\\ndescription: Python, SQL, PostgreSQL, R. Designed and implemented custom software solutions using Python, SQL, and Firebase to address client-specific needs. User R to analyze data and process large volumes of information to do introductory data analisys and EDA (exploratory analisys) for a machine learning proyect. Cleaned and processed data using Python and R saving over 250 man hours on cleaning and loading data. Developed a web application using Django and React, enhancing user experience and engagement. Collaborated with cross-functional teams to gather requirements and deliver solutions that met client expectations. Created and maintained documentation for software development processes, ensuring knowledge transfer and project continuity.\", 0.9322342490872968], [\"type: education\\\\ncompany: ITBA\\\\nlocation: Argentina\\\\nrole: \\\\nstart_date: 01/03/2023\\\\nend_date: 01/09/2023\\\\ndescription: Full Stack Developer\", 0.9540665775315647], [\"type: info\\\\ncompany: phone\\\\nlocation: \\\\nrole: \\\\nstart_date: \\\\nend_date: \\\\ndescription: +54 9 11 3465-2325\", 0.958299691535799]]', name='PGVectorTool', id='b744998c-05d5-4757-84ac-e30ecd3576df', tool_call_id='197e1eac-4d31-4c3d-8242-154fc57874ee'),\n",
       "  ToolMessage(content=[], name='PGVectorTool', id='fa076749-2ad0-4cf7-8989-3709a0808605', tool_call_id='eb65a1a3-2cc0-4249-89a7-477a6ced04aa'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'PGVectorTool', 'arguments': '{\"query\": \"achievements of a Data Scientist in applying machine learning techniques, improving business metrics, and presenting results\", \"n_results\": 5}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b3f95-fe30-7f53-a061-e41ca5dee39f-0', tool_calls=[{'name': 'PGVectorTool', 'args': {'n_results': 5, 'query': 'responsibilities of a Data Scientist using Python, R, SQL, pandas, sklearn, matplotlib, pyplot, seaborn, regression, classification, time series, trees, ensembles, neural networks, clustering, dimensionality reduction'}, 'id': 'b46fc13b-43d7-49ff-92a8-2667b6ba19e4', 'type': 'tool_call'}, {'name': 'PGVectorTool', 'args': {'query': 'skills for a Data Scientist including predictive models, generative AI, supervised and unsupervised models, data balancing, machine learning, basic statistics, programming best practices, cloud platforms, Azure', 'n_results': 5}, 'id': 'a1625ed3-13d7-489e-96b3-51c1db364e2f', 'type': 'tool_call'}, {'name': 'PGVectorTool', 'args': {'query': 'achievements of a Data Scientist in applying machine learning techniques, improving business metrics, and presenting results', 'n_results': 5}, 'id': 'db6b6452-99ed-4cfd-bcf4-c9c1af3274d1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3246, 'output_tokens': 157, 'total_tokens': 3403, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities, collaborated on the proyect with two other engineers using git and dividing tasks on sprints. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns, saving over 120 man hours on cleaning and loading data.\", 0.7430546964559214], [\"type: proyect\\\\ncompany: Better Resume\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/03/2025\\\\nend_date: 30/03/2025\\\\ndescription: Python, Vector Database, fastapi. Developed a web app that the user can use to create a resume using LLMs and RAGs to generate a resume tailored to the specific position description. It was built using ChromaDB for the vector database, a locally hosted model and fastapi with a basic javascript frontend. The data is currently stored in a csv so the user can load and modify the data on a familiar format.\", 0.7497555413799798], [\"type: job\\\\ncompany: Mouse Soluciones\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/02/2020\\\\nend_date: 01/08/2024\\\\ndescription: Python, SQL, PostgreSQL, R. Designed and implemented custom software solutions using Python, SQL, and Firebase to address client-specific needs. User R to analyze data and process large volumes of information to do introductory data analisys and EDA (exploratory analisys) for a machine learning proyect. Cleaned and processed data using Python and R saving over 250 man hours on cleaning and loading data. Developed a web application using Django and React, enhancing user experience and engagement. Collaborated with cross-functional teams to gather requirements and deliver solutions that met client expectations. Created and maintained documentation for software development processes, ensuring knowledge transfer and project continuity.\", 0.7527718978580251], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup‚Äôs backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita√∫ Bank and Cebra Jugueter√≠as. Created interactive dashboards using Power BI, enabling real-time decision-making. Created automated tasks using azure functions to reduce the time spent on manual tasks by 80%.\", 0.7649961341186778], [\"type: non-profit\\\\ncompany: CEITBA\\\\nlocation: Argentina\\\\nrole: Lead Developer\\\\nstart_date: 01/03/2021\\\\nend_date: 01/03/2025\\\\ndescription: Python, Javascript, React, Dart, Flutter. Led a team of five in developing a Flutter-based mobile application for CEITBA, utilizing Firebase and Google Cloud for scalability. Automated administrative tasks with AI-based tools, optimizing student registrations, withdrawals, and query responses. Team player, dividing tasks and solving conflicts within the group to push the project forward\", 0.7978716582775581]]', name='PGVectorTool', id='f1876ef6-4305-420c-b325-a945fca09916', tool_call_id='b46fc13b-43d7-49ff-92a8-2667b6ba19e4'),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Mouse Soluciones\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/02/2020\\\\nend_date: 01/08/2024\\\\ndescription: Python, SQL, PostgreSQL, R. Designed and implemented custom software solutions using Python, SQL, and Firebase to address client-specific needs. User R to analyze data and process large volumes of information to do introductory data analisys and EDA (exploratory analisys) for a machine learning proyect. Cleaned and processed data using Python and R saving over 250 man hours on cleaning and loading data. Developed a web application using Django and React, enhancing user experience and engagement. Collaborated with cross-functional teams to gather requirements and deliver solutions that met client expectations. Created and maintained documentation for software development processes, ensuring knowledge transfer and project continuity.\", 0.7586899622710588], [\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities, collaborated on the proyect with two other engineers using git and dividing tasks on sprints. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns, saving over 120 man hours on cleaning and loading data.\", 0.7970819391563122], [\"type: contract\\\\ncompany: Somos Feed\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/07/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, Django, Javascript, SQLite, Pandas, Numpy, XGBoost, SKlearn, Matplot lib, Plotly. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week\\'s data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solution also freed time of other data scientists in the team that were previously just cleaning data. Created a Machine Learning pipeline that auto adjust and pick the best regresor based on last\\'s week behavior to adjust to a growing and constanly changing database. Did exploratory data analysis (EDA) and applied statistical analysis on the results to know where to look into the data and make the most impact without wasting resources and time.\", 0.7992870998894087], [\"type: part-time\\\\ncompany: ITBA\\\\nlocation: Argentina\\\\nrole: Data structure\\'s Teachers assistan\\\\nstart_date: 01/03/2023\\\\nend_date: \\\\ndescription: Python, matplotlib, PyQT, Threading, asyncio, requests, aiohttp. Assisted the teacher in the Data Structures course, helping students with their doubts and explaining the theory behind the algorithms. Also helped in the creation of the final project of the courses. The projects were about creating UIs for a goverment database that had to allow for the creation and persistence of data in a local database.\", 0.8075912083941282], [\"type: proyect\\\\ncompany: Better Resume\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/03/2025\\\\nend_date: 30/03/2025\\\\ndescription: Python, Vector Database, fastapi. Developed a web app that the user can use to create a resume using LLMs and RAGs to generate a resume tailored to the specific position description. It was built using ChromaDB for the vector database, a locally hosted model and fastapi with a basic javascript frontend. The data is currently stored in a csv so the user can load and modify the data on a familiar format.\", 0.8171355717864894]]', name='PGVectorTool', id='93ff3c4e-dc7d-4e0b-abef-3cbba3534e25', tool_call_id='a1625ed3-13d7-489e-96b3-51c1db364e2f'),\n",
       "  ToolMessage(content='[[\"type: job\\\\ncompany: Mouse Soluciones\\\\nlocation: Argentina\\\\nrole: Software Developer\\\\nstart_date: 01/02/2020\\\\nend_date: 01/08/2024\\\\ndescription: Python, SQL, PostgreSQL, R. Designed and implemented custom software solutions using Python, SQL, and Firebase to address client-specific needs. User R to analyze data and process large volumes of information to do introductory data analisys and EDA (exploratory analisys) for a machine learning proyect. Cleaned and processed data using Python and R saving over 250 man hours on cleaning and loading data. Developed a web application using Django and React, enhancing user experience and engagement. Collaborated with cross-functional teams to gather requirements and deliver solutions that met client expectations. Created and maintained documentation for software development processes, ensuring knowledge transfer and project continuity.\", 0.7688404216157064], [\"type: part-time\\\\ncompany: ITBA\\\\nlocation: Argentina\\\\nrole: Data structure\\'s Teachers assistan\\\\nstart_date: 01/03/2023\\\\nend_date: \\\\ndescription: Python, matplotlib, PyQT, Threading, asyncio, requests, aiohttp. Assisted the teacher in the Data Structures course, helping students with their doubts and explaining the theory behind the algorithms. Also helped in the creation of the final project of the courses. The projects were about creating UIs for a goverment database that had to allow for the creation and persistence of data in a local database.\", 0.7690860603006686], [\"type: job\\\\ncompany: Turbodato\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/01/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, SQL, Azure Database. Designed and built the startup‚Äôs backend infrastructure with a focus on scalability and automation. Developed web scraping bots to collect competitive business intelligence for clients like Ita√∫ Bank and Cebra Jugueter√≠as. Created interactive dashboards using Power BI, enabling real-time decision-making. Created automated tasks using azure functions to reduce the time spent on manual tasks by 80%.\", 0.7850755109125652], [\"type: job\\\\ncompany: Accenture\\\\nlocation: Argentina\\\\nrole: Data Engineer\\\\nstart_date: 01/08/2024\\\\nend_date: \\\\ndescription: Python, SQL, Javascript, Google sheets. Developed and integrated AI-driven solutions for a large bank, utilizing LangChain and RAGs to enhance LLM capabilities, collaborated on the proyect with two other engineers using git and dividing tasks on sprints. Implemented voice message processing and structured data queries, improving system response accuracy. Collaborated in Agile sprints, contributing to increased system efficiency and performance. Used Data scraping techniques to gather information for my vector database (chromaDB) and deployed it on Azure using github actions with testing and CI/CD to ensure consistency on the product. Also worked on ETL pipelines to upload and generate a system to detect anomalies in the machine in order to prevent sudden breakdowns, saving over 120 man hours on cleaning and loading data.\", 0.7867342904761653], [\"type: contract\\\\ncompany: Somos Feed\\\\nlocation: Argentina\\\\nrole: Data Architect\\\\nstart_date: 01/07/2024\\\\nend_date: 01/12/2024\\\\ndescription: Python, Django, Javascript, SQLite, Pandas, Numpy, XGBoost, SKlearn, Matplot lib, Plotly. Designed and built the backend infrastructure on Django for the company to automate the process of data gathering from all its different providers. Generated the ETL pipeline to load the information onto the database from google sheet files and created the machine learning algorithm to be trained weekly on the previous week\\'s data to estimate sales and reduce waste, genrating up to a 68% of waste reduction and increasing the benefits of the company by 30%. The solution also freed time of other data scientists in the team that were previously just cleaning data. Created a Machine Learning pipeline that auto adjust and pick the best regresor based on last\\'s week behavior to adjust to a growing and constanly changing database. Did exploratory data analysis (EDA) and applied statistical analysis on the results to know where to look into the data and make the most impact without wasting resources and time.\", 0.7908052141063024]]', name='PGVectorTool', id='764d86e3-eb29-4785-9d85-67909d4857e2', tool_call_id='db6b6452-99ed-4cfd-bcf4-c9c1af3274d1'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'ResumeOutputFormat', 'arguments': '{\"language\": \"ES\", \"resume_section\": {\"education\": [{\"institution\": \"ITBA\", \"dates\": \"01/01/2021 - 01/07/2025\", \"degree\": \"Data Science\"}, {\"institution\": \"ITBA\", \"degree\": \"Full Stack Developer\", \"dates\": \"01/03/2023 - 01/09/2023\"}], \"professional_summary\": \"Data Scientist con 2 a\\\\u00f1os de experiencia en el desarrollo e implementaci\\\\u00f3n de modelos predictivos y experiencia en IA Generativa. Experto en Python, R y SQL, con un profundo conocimiento de librer\\\\u00edas como pandas, sklearn, matplotlib, pyplot y seaborn. S\\\\u00f3lida experiencia en t\\\\u00e9cnicas de machine learning, incluyendo modelos de regresi\\\\u00f3n, clasificaci\\\\u00f3n, series temporales, \\\\u00e1rboles, ensambles, redes neuronales, clustering y reducci\\\\u00f3n de dimensionalidad. Capacidad demostrada para presentar resultados de forma asertiva y poseo conocimientos sobre modelos supervisados y no supervisados, evaluaci\\\\u00f3n de modelos, balanceo de datos y buenas pr\\\\u00e1cticas de programaci\\\\u00f3n. Busco aplicar mis habilidades en una empresa l\\\\u00edder en tecnolog\\\\u00eda y negocios.\", \"skills\": [{\"name\": \"Machine Learning\", \"description\": \"Experiencia en el desarrollo y aplicaci\\\\u00f3n de modelos predictivos, incluyendo regresi\\\\u00f3n, clasificaci\\\\u00f3n, series temporales, \\\\u00e1rboles, ensambles, redes neuronales, clustering y reducci\\\\u00f3n de dimensionalidad. Conocimiento de modelos supervisados y no supervisados, evaluaci\\\\u00f3n de modelos y balanceo de datos.\"}, {\"name\": \"Python y R\", \"description\": \"Desarrollo con Python y R, con experiencia en librer\\\\u00edas como pandas y sklearn para manipulaci\\\\u00f3n de datos y modelado. Habilidad en librer\\\\u00edas de visualizaci\\\\u00f3n como matplotlib, pyplot y seaborn para la presentaci\\\\u00f3n de resultados.\"}, {\"description\": \"Lenguaje de consulta SQL para extracci\\\\u00f3n y manipulaci\\\\u00f3n de datos. Experiencia con bases de datos PostgreSQL y Azure Database.\", \"name\": \"SQL y Bases de Datos\"}, {\"name\": \"IA Generativa\", \"description\": \"Experiencia en aplicaciones de IA Generativa, incluyendo el uso de LangChain y RAGs para mejorar las capacidades de los modelos de lenguaje (LLMs).\"}, {\"name\": \"Cloud Platforms\", \"description\": \"Manejo de plataformas Cloud, con preferencia por Azure, incluyendo el uso de Azure Functions y Azure Database.\"}], \"experience\": [{\"start_date\": \"01/08/2024\", \"end_date\": \"\", \"company\": \"Accenture\", \"location\": \"Argentina\", \"description\": \"\\\\u2022 Desarroll\\\\u00e9 e integr\\\\u00e9 soluciones impulsadas por IA para un gran banco, utilizando LangChain y RAGs para mejorar las capacidades de LLM.\\\\n\\\\u2022 Implement\\\\u00e9 el procesamiento de mensajes de voz y consultas de datos estructurados, mejorando la precisi\\\\u00f3n de la respuesta del sistema.\\\\n\\\\u2022 Utilic\\\\u00e9 t\\\\u00e9cnicas de Data scraping para recopilar informaci\\\\u00f3n para mi base de datos vectorial (chromaDB) y la desplegu\\\\u00e9 en Azure.\\\\n\\\\u2022 Trabaj\\\\u00e9 en pipelines ETL para generar un sistema que detecta anomal\\\\u00edas en la maquinaria, previniendo aver\\\\u00edas y ahorrando m\\\\u00e1s de 120 horas de trabajo humano en limpieza y carga de datos.\", \"position\": \"Data Engineer\"}, {\"start_date\": \"01/07/2024\", \"description\": \"\\\\u2022 Dise\\\\u00f1\\\\u00e9 y constru\\\\u00ed la infraestructura backend en Django para automatizar la recopilaci\\\\u00f3n de datos de diversos proveedores.\\\\n\\\\u2022 Gener\\\\u00e9 el pipeline ETL para cargar informaci\\\\u00f3n desde archivos de Google Sheets y cre\\\\u00e9 un algoritmo de machine learning para estimar ventas y reducir desperdicios, logrando una reducci\\\\u00f3n de hasta 68% en desperdicios y un aumento del 30% en beneficios.\\\\n\\\\u2022 Cre\\\\u00e9 un pipeline de Machine Learning que se autoajusta y selecciona el mejor regresor seg\\\\u00fan el comportamiento de la semana anterior para adaptarse a una base de datos en constante crecimiento y cambio.\\\\n\\\\u2022 Realic\\\\u00e9 an\\\\u00e1lisis exploratorio de datos (EDA) y an\\\\u00e1lisis estad\\\\u00edsticos para optimizar el impacto sin desperdiciar recursos.\", \"location\": \"Argentina\", \"company\": \"Somos Feed\", \"position\": \"Data Architect\", \"end_date\": \"01/12/2024\"}, {\"description\": \"\\\\u2022 Dise\\\\u00f1\\\\u00e9 y constru\\\\u00ed la infraestructura backend de la startup con enfoque en escalabilidad y automatizaci\\\\u00f3n.\\\\n\\\\u2022 Desarroll\\\\u00e9 web scraping bots para recopilar inteligencia de negocios competitiva para clientes como Ita\\\\u00fa Bank y Cebra Jugueter\\\\u00edas.\\\\n\\\\u2022 Cre\\\\u00e9 dashboards interactivos utilizando Power BI, permitiendo la toma de decisiones en tiempo real.\\\\n\\\\u2022 Implement\\\\u00e9 tareas automatizadas usando Azure functions para reducir el tiempo dedicado a tareas manuales en un 80%.\", \"start_date\": \"01/01/2024\", \"company\": \"Turbodato\", \"end_date\": \"01/12/2024\", \"location\": \"Argentina\", \"position\": \"Data Architect\"}], \"title\": \"Data Scientist\"}}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b3f96-1bd8-7041-875f-f5c6c1989644-0', tool_calls=[{'name': 'ResumeOutputFormat', 'args': {'language': 'ES', 'resume_section': {'education': [{'institution': 'ITBA', 'dates': '01/01/2021 - 01/07/2025', 'degree': 'Data Science'}, {'institution': 'ITBA', 'degree': 'Full Stack Developer', 'dates': '01/03/2023 - 01/09/2023'}], 'professional_summary': 'Data Scientist con 2 a√±os de experiencia en el desarrollo e implementaci√≥n de modelos predictivos y experiencia en IA Generativa. Experto en Python, R y SQL, con un profundo conocimiento de librer√≠as como pandas, sklearn, matplotlib, pyplot y seaborn. S√≥lida experiencia en t√©cnicas de machine learning, incluyendo modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Capacidad demostrada para presentar resultados de forma asertiva y poseo conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos y buenas pr√°cticas de programaci√≥n. Busco aplicar mis habilidades en una empresa l√≠der en tecnolog√≠a y negocios.', 'skills': [{'name': 'Machine Learning', 'description': 'Experiencia en el desarrollo y aplicaci√≥n de modelos predictivos, incluyendo regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Conocimiento de modelos supervisados y no supervisados, evaluaci√≥n de modelos y balanceo de datos.'}, {'name': 'Python y R', 'description': 'Desarrollo con Python y R, con experiencia en librer√≠as como pandas y sklearn para manipulaci√≥n de datos y modelado. Habilidad en librer√≠as de visualizaci√≥n como matplotlib, pyplot y seaborn para la presentaci√≥n de resultados.'}, {'description': 'Lenguaje de consulta SQL para extracci√≥n y manipulaci√≥n de datos. Experiencia con bases de datos PostgreSQL y Azure Database.', 'name': 'SQL y Bases de Datos'}, {'name': 'IA Generativa', 'description': 'Experiencia en aplicaciones de IA Generativa, incluyendo el uso de LangChain y RAGs para mejorar las capacidades de los modelos de lenguaje (LLMs).'}, {'name': 'Cloud Platforms', 'description': 'Manejo de plataformas Cloud, con preferencia por Azure, incluyendo el uso de Azure Functions y Azure Database.'}], 'experience': [{'start_date': '01/08/2024', 'end_date': '', 'company': 'Accenture', 'location': 'Argentina', 'description': '‚Ä¢ Desarroll√© e integr√© soluciones impulsadas por IA para un gran banco, utilizando LangChain y RAGs para mejorar las capacidades de LLM.\\n‚Ä¢ Implement√© el procesamiento de mensajes de voz y consultas de datos estructurados, mejorando la precisi√≥n de la respuesta del sistema.\\n‚Ä¢ Utilic√© t√©cnicas de Data scraping para recopilar informaci√≥n para mi base de datos vectorial (chromaDB) y la desplegu√© en Azure.\\n‚Ä¢ Trabaj√© en pipelines ETL para generar un sistema que detecta anomal√≠as en la maquinaria, previniendo aver√≠as y ahorrando m√°s de 120 horas de trabajo humano en limpieza y carga de datos.', 'position': 'Data Engineer'}, {'start_date': '01/07/2024', 'description': '‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend en Django para automatizar la recopilaci√≥n de datos de diversos proveedores.\\n‚Ä¢ Gener√© el pipeline ETL para cargar informaci√≥n desde archivos de Google Sheets y cre√© un algoritmo de machine learning para estimar ventas y reducir desperdicios, logrando una reducci√≥n de hasta 68% en desperdicios y un aumento del 30% en beneficios.\\n‚Ä¢ Cre√© un pipeline de Machine Learning que se autoajusta y selecciona el mejor regresor seg√∫n el comportamiento de la semana anterior para adaptarse a una base de datos en constante crecimiento y cambio.\\n‚Ä¢ Realic√© an√°lisis exploratorio de datos (EDA) y an√°lisis estad√≠sticos para optimizar el impacto sin desperdiciar recursos.', 'location': 'Argentina', 'company': 'Somos Feed', 'position': 'Data Architect', 'end_date': '01/12/2024'}, {'description': '‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend de la startup con enfoque en escalabilidad y automatizaci√≥n.\\n‚Ä¢ Desarroll√© web scraping bots para recopilar inteligencia de negocios competitiva para clientes como Ita√∫ Bank y Cebra Jugueter√≠as.\\n‚Ä¢ Cre√© dashboards interactivos utilizando Power BI, permitiendo la toma de decisiones en tiempo real.\\n‚Ä¢ Implement√© tareas automatizadas usando Azure functions para reducir el tiempo dedicado a tareas manuales en un 80%.', 'start_date': '01/01/2024', 'company': 'Turbodato', 'end_date': '01/12/2024', 'location': 'Argentina', 'position': 'Data Architect'}], 'title': 'Data Scientist'}}, 'id': '9304fe7a-2a58-46c0-b037-aae9f039ee8b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6419, 'output_tokens': 1064, 'total_tokens': 7483, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"Returning structured response: language='ES' resume_section=ResumeSection(title='Data Scientist', professional_summary='Data Scientist con 2 a√±os de experiencia en el desarrollo e implementaci√≥n de modelos predictivos y experiencia en IA Generativa. Experto en Python, R y SQL, con un profundo conocimiento de librer√≠as como pandas, sklearn, matplotlib, pyplot y seaborn. S√≥lida experiencia en t√©cnicas de machine learning, incluyendo modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Capacidad demostrada para presentar resultados de forma asertiva y poseo conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos y buenas pr√°cticas de programaci√≥n. Busco aplicar mis habilidades en una empresa l√≠der en tecnolog√≠a y negocios.', experience=[JobExperience(position='Data Engineer', company='Accenture', location='Argentina', start_date='01/08/2024', end_date='', description='‚Ä¢ Desarroll√© e integr√© soluciones impulsadas por IA para un gran banco, utilizando LangChain y RAGs para mejorar las capacidades de LLM.\\\\n‚Ä¢ Implement√© el procesamiento de mensajes de voz y consultas de datos estructurados, mejorando la precisi√≥n de la respuesta del sistema.\\\\n‚Ä¢ Utilic√© t√©cnicas de Data scraping para recopilar informaci√≥n para mi base de datos vectorial (chromaDB) y la desplegu√© en Azure.\\\\n‚Ä¢ Trabaj√© en pipelines ETL para generar un sistema que detecta anomal√≠as en la maquinaria, previniendo aver√≠as y ahorrando m√°s de 120 horas de trabajo humano en limpieza y carga de datos.'), JobExperience(position='Data Architect', company='Somos Feed', location='Argentina', start_date='01/07/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend en Django para automatizar la recopilaci√≥n de datos de diversos proveedores.\\\\n‚Ä¢ Gener√© el pipeline ETL para cargar informaci√≥n desde archivos de Google Sheets y cre√© un algoritmo de machine learning para estimar ventas y reducir desperdicios, logrando una reducci√≥n de hasta 68% en desperdicios y un aumento del 30% en beneficios.\\\\n‚Ä¢ Cre√© un pipeline de Machine Learning que se autoajusta y selecciona el mejor regresor seg√∫n el comportamiento de la semana anterior para adaptarse a una base de datos en constante crecimiento y cambio.\\\\n‚Ä¢ Realic√© an√°lisis exploratorio de datos (EDA) y an√°lisis estad√≠sticos para optimizar el impacto sin desperdiciar recursos.'), JobExperience(position='Data Architect', company='Turbodato', location='Argentina', start_date='01/01/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend de la startup con enfoque en escalabilidad y automatizaci√≥n.\\\\n‚Ä¢ Desarroll√© web scraping bots para recopilar inteligencia de negocios competitiva para clientes como Ita√∫ Bank y Cebra Jugueter√≠as.\\\\n‚Ä¢ Cre√© dashboards interactivos utilizando Power BI, permitiendo la toma de decisiones en tiempo real.\\\\n‚Ä¢ Implement√© tareas automatizadas usando Azure functions para reducir el tiempo dedicado a tareas manuales en un 80%.')], skills=[Skill(name='Machine Learning', description='Experiencia en el desarrollo y aplicaci√≥n de modelos predictivos, incluyendo regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Conocimiento de modelos supervisados y no supervisados, evaluaci√≥n de modelos y balanceo de datos.'), Skill(name='Python y R', description='Desarrollo con Python y R, con experiencia en librer√≠as como pandas y sklearn para manipulaci√≥n de datos y modelado. Habilidad en librer√≠as de visualizaci√≥n como matplotlib, pyplot y seaborn para la presentaci√≥n de resultados.'), Skill(name='SQL y Bases de Datos', description='Lenguaje de consulta SQL para extracci√≥n y manipulaci√≥n de datos. Experiencia con bases de datos PostgreSQL y Azure Database.'), Skill(name='IA Generativa', description='Experiencia en aplicaciones de IA Generativa, incluyendo el uso de LangChain y RAGs para mejorar las capacidades de los modelos de lenguaje (LLMs).'), Skill(name='Cloud Platforms', description='Manejo de plataformas Cloud, con preferencia por Azure, incluyendo el uso de Azure Functions y Azure Database.')], education=[Education(institution='ITBA', degree='Data Science', dates='01/01/2021 - 01/07/2025'), Education(institution='ITBA', degree='Full Stack Developer', dates='01/03/2023 - 01/09/2023')])\", name='ResumeOutputFormat', id='381876e5-b41e-4e63-95af-2b6ba388052b', tool_call_id='9304fe7a-2a58-46c0-b037-aae9f039ee8b')],\n",
       " 'user_id': 'ian_test',\n",
       " 'structured_response': ResumeOutputFormat(language='ES', resume_section=ResumeSection(title='Data Scientist', professional_summary='Data Scientist con 2 a√±os de experiencia en el desarrollo e implementaci√≥n de modelos predictivos y experiencia en IA Generativa. Experto en Python, R y SQL, con un profundo conocimiento de librer√≠as como pandas, sklearn, matplotlib, pyplot y seaborn. S√≥lida experiencia en t√©cnicas de machine learning, incluyendo modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Capacidad demostrada para presentar resultados de forma asertiva y poseo conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos y buenas pr√°cticas de programaci√≥n. Busco aplicar mis habilidades en una empresa l√≠der en tecnolog√≠a y negocios.', experience=[JobExperience(position='Data Engineer', company='Accenture', location='Argentina', start_date='01/08/2024', end_date='', description='‚Ä¢ Desarroll√© e integr√© soluciones impulsadas por IA para un gran banco, utilizando LangChain y RAGs para mejorar las capacidades de LLM.\\n‚Ä¢ Implement√© el procesamiento de mensajes de voz y consultas de datos estructurados, mejorando la precisi√≥n de la respuesta del sistema.\\n‚Ä¢ Utilic√© t√©cnicas de Data scraping para recopilar informaci√≥n para mi base de datos vectorial (chromaDB) y la desplegu√© en Azure.\\n‚Ä¢ Trabaj√© en pipelines ETL para generar un sistema que detecta anomal√≠as en la maquinaria, previniendo aver√≠as y ahorrando m√°s de 120 horas de trabajo humano en limpieza y carga de datos.'), JobExperience(position='Data Architect', company='Somos Feed', location='Argentina', start_date='01/07/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend en Django para automatizar la recopilaci√≥n de datos de diversos proveedores.\\n‚Ä¢ Gener√© el pipeline ETL para cargar informaci√≥n desde archivos de Google Sheets y cre√© un algoritmo de machine learning para estimar ventas y reducir desperdicios, logrando una reducci√≥n de hasta 68% en desperdicios y un aumento del 30% en beneficios.\\n‚Ä¢ Cre√© un pipeline de Machine Learning que se autoajusta y selecciona el mejor regresor seg√∫n el comportamiento de la semana anterior para adaptarse a una base de datos en constante crecimiento y cambio.\\n‚Ä¢ Realic√© an√°lisis exploratorio de datos (EDA) y an√°lisis estad√≠sticos para optimizar el impacto sin desperdiciar recursos.'), JobExperience(position='Data Architect', company='Turbodato', location='Argentina', start_date='01/01/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend de la startup con enfoque en escalabilidad y automatizaci√≥n.\\n‚Ä¢ Desarroll√© web scraping bots para recopilar inteligencia de negocios competitiva para clientes como Ita√∫ Bank y Cebra Jugueter√≠as.\\n‚Ä¢ Cre√© dashboards interactivos utilizando Power BI, permitiendo la toma de decisiones en tiempo real.\\n‚Ä¢ Implement√© tareas automatizadas usando Azure functions para reducir el tiempo dedicado a tareas manuales en un 80%.')], skills=[Skill(name='Machine Learning', description='Experiencia en el desarrollo y aplicaci√≥n de modelos predictivos, incluyendo regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Conocimiento de modelos supervisados y no supervisados, evaluaci√≥n de modelos y balanceo de datos.'), Skill(name='Python y R', description='Desarrollo con Python y R, con experiencia en librer√≠as como pandas y sklearn para manipulaci√≥n de datos y modelado. Habilidad en librer√≠as de visualizaci√≥n como matplotlib, pyplot y seaborn para la presentaci√≥n de resultados.'), Skill(name='SQL y Bases de Datos', description='Lenguaje de consulta SQL para extracci√≥n y manipulaci√≥n de datos. Experiencia con bases de datos PostgreSQL y Azure Database.'), Skill(name='IA Generativa', description='Experiencia en aplicaciones de IA Generativa, incluyendo el uso de LangChain y RAGs para mejorar las capacidades de los modelos de lenguaje (LLMs).'), Skill(name='Cloud Platforms', description='Manejo de plataformas Cloud, con preferencia por Azure, incluyendo el uso de Azure Functions y Azure Database.')], education=[Education(institution='ITBA', degree='Data Science', dates='01/01/2021 - 01/07/2025'), Education(institution='ITBA', degree='Full Stack Developer', dates='01/03/2023 - 01/09/2023')]))}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from llm.state import State\n",
    "s = State(messages=[SystemMessage(bot.llm.JOB_PROMPT),HumanMessage(JOB_PROMPT_SPANISH)], user_id=\"ian_test\")\n",
    "res = await bot.llm.ainvoke(s)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResumeOutputFormat(language='ES', resume_section=ResumeSection(title='Data Scientist', professional_summary='Data Scientist con 2 a√±os de experiencia en el desarrollo e implementaci√≥n de modelos predictivos y experiencia en IA Generativa. Experto en Python, R y SQL, con un profundo conocimiento de librer√≠as como pandas, sklearn, matplotlib, pyplot y seaborn. S√≥lida experiencia en t√©cnicas de machine learning, incluyendo modelos de regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Capacidad demostrada para presentar resultados de forma asertiva y poseo conocimientos sobre modelos supervisados y no supervisados, evaluaci√≥n de modelos, balanceo de datos y buenas pr√°cticas de programaci√≥n. Busco aplicar mis habilidades en una empresa l√≠der en tecnolog√≠a y negocios.', experience=[JobExperience(position='Data Engineer', company='Accenture', location='Argentina', start_date='01/08/2024', end_date='', description='‚Ä¢ Desarroll√© e integr√© soluciones impulsadas por IA para un gran banco, utilizando LangChain y RAGs para mejorar las capacidades de LLM.\\n‚Ä¢ Implement√© el procesamiento de mensajes de voz y consultas de datos estructurados, mejorando la precisi√≥n de la respuesta del sistema.\\n‚Ä¢ Utilic√© t√©cnicas de Data scraping para recopilar informaci√≥n para mi base de datos vectorial (chromaDB) y la desplegu√© en Azure.\\n‚Ä¢ Trabaj√© en pipelines ETL para generar un sistema que detecta anomal√≠as en la maquinaria, previniendo aver√≠as y ahorrando m√°s de 120 horas de trabajo humano en limpieza y carga de datos.'), JobExperience(position='Data Architect', company='Somos Feed', location='Argentina', start_date='01/07/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend en Django para automatizar la recopilaci√≥n de datos de diversos proveedores.\\n‚Ä¢ Gener√© el pipeline ETL para cargar informaci√≥n desde archivos de Google Sheets y cre√© un algoritmo de machine learning para estimar ventas y reducir desperdicios, logrando una reducci√≥n de hasta 68% en desperdicios y un aumento del 30% en beneficios.\\n‚Ä¢ Cre√© un pipeline de Machine Learning que se autoajusta y selecciona el mejor regresor seg√∫n el comportamiento de la semana anterior para adaptarse a una base de datos en constante crecimiento y cambio.\\n‚Ä¢ Realic√© an√°lisis exploratorio de datos (EDA) y an√°lisis estad√≠sticos para optimizar el impacto sin desperdiciar recursos.'), JobExperience(position='Data Architect', company='Turbodato', location='Argentina', start_date='01/01/2024', end_date='01/12/2024', description='‚Ä¢ Dise√±√© y constru√≠ la infraestructura backend de la startup con enfoque en escalabilidad y automatizaci√≥n.\\n‚Ä¢ Desarroll√© web scraping bots para recopilar inteligencia de negocios competitiva para clientes como Ita√∫ Bank y Cebra Jugueter√≠as.\\n‚Ä¢ Cre√© dashboards interactivos utilizando Power BI, permitiendo la toma de decisiones en tiempo real.\\n‚Ä¢ Implement√© tareas automatizadas usando Azure functions para reducir el tiempo dedicado a tareas manuales en un 80%.')], skills=[Skill(name='Machine Learning', description='Experiencia en el desarrollo y aplicaci√≥n de modelos predictivos, incluyendo regresi√≥n, clasificaci√≥n, series temporales, √°rboles, ensambles, redes neuronales, clustering y reducci√≥n de dimensionalidad. Conocimiento de modelos supervisados y no supervisados, evaluaci√≥n de modelos y balanceo de datos.'), Skill(name='Python y R', description='Desarrollo con Python y R, con experiencia en librer√≠as como pandas y sklearn para manipulaci√≥n de datos y modelado. Habilidad en librer√≠as de visualizaci√≥n como matplotlib, pyplot y seaborn para la presentaci√≥n de resultados.'), Skill(name='SQL y Bases de Datos', description='Lenguaje de consulta SQL para extracci√≥n y manipulaci√≥n de datos. Experiencia con bases de datos PostgreSQL y Azure Database.'), Skill(name='IA Generativa', description='Experiencia en aplicaciones de IA Generativa, incluyendo el uso de LangChain y RAGs para mejorar las capacidades de los modelos de lenguaje (LLMs).'), Skill(name='Cloud Platforms', description='Manejo de plataformas Cloud, con preferencia por Azure, incluyendo el uso de Azure Functions y Azure Database.')], education=[Education(institution='ITBA', degree='Data Science', dates='01/01/2021 - 01/07/2025'), Education(institution='ITBA', degree='Full Stack Developer', dates='01/03/2023 - 01/09/2023')]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"structured_response\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_resume.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.writer.write(res[\"structured_response\"], \"output_resume.pdf\",to_pdf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
